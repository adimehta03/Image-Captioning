# Image Captioning
___
Implementation of a Image Captioning Model using Transfer Learning and Recurrent Neural Networks

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/iVishalr/Image-Captioning.ipynb)

## Requirements
___
The following libraries are required to run the code : 
  1. Tensorflow
  2. Keras
  3. Numpy
  4. Pandas
  5. OpenCV
  6. Matplotlib
  7. Tqdm

### Dataset
___

The neural network has been trained on Flicker8K Dataset. This dataset has been obtained from Kaggle. The link to this dataset is given below. Please download the dataset from the given link and place them in your project directory.

Link : https://www.kaggle.com/ming666/flicker8k-dataset

### Training
___

Training the neural network takes a really long time. Training depends on your system's capability. The neural network has been trained on Nvidia Tesla K80 GPUs for about 3 days. This could vary from system to system. It is recommended to use a GPU of some sort to train this model.

### Contribution
___

Contributers are free to make changes in the code either to imporve it or correct some of the bugs that may be present in the code. Please make a pull request before you edit the code. Avoid making changes in the master branch.

For downloading the weights for the Neural Network, please contact me at my email address given below

Email ID : *vishalramesh01[at]gmail.com*

*NOTE : The model weights will not be given to everyone. The chances of getting one will be based on your contributions to the       project.*

